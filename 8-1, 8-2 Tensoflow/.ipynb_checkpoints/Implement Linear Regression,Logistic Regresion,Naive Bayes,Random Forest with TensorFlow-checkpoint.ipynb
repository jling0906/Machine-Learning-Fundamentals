{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "ad5e3d9aa1b4f9cc022ca21d923417d325660702",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "e7c17eed09df55a898d4124fbb7b4b4ca6e360db",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a219891a4590138934157cc7e3cd56b5fbdd66f8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "fdc1becb5d490de5e7c5829e33a40a6b7b549429",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "6242a5b0bb7138f484a96fdfa1580a4ec100d2bf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "1e9b21480718ec2ed9c09b522bcadde3227cebb3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "2eb01a9903d3f14db76e8d9ab9055ad9cdd78b55",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "0b4e542e6e9ba0b1cf03a6029b5fc6deb39c8ea9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "cb7c019e70b3447a54f0e58f7c5e99019bd5e019",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(x.eval())\n",
    "    print(y.eval())\n",
    "    result = sess.run(f, feed_dict={x:1, y:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "2907d830ca0ecddb72324e8c6360833915902bec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1a76ec0610c027253b1676429afb7f8c30281933",
    "collapsed": true
   },
   "source": [
    "### 用tensorflow 来实现linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "0ae375c115b80f77e218be416d7666f09ff2c469",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_decision_boundary(X, model):\n",
    "    h = .02 \n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                       np.arange(y_min, y_max, h))\n",
    "\n",
    "\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "\n",
    "def f(X):\n",
    "    \"\"\"\n",
    "    input: x\n",
    "    output: y = 3x + 4\n",
    "    \"\"\"\n",
    "    return 3*X + 4\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "4cd3bc255e32725609049e39305b65c25f471b64",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 40\n",
    "noise_level = 0.8\n",
    "trainX = np.linspace(-4.0, 4.0, N)\n",
    "np.random.shuffle(trainX)\n",
    "trainY = f(trainX) + np.random.randn(N) * noise_level\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "e90666afe12c86841f37eb12b35679866fa87e7f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "3f0f0c1f681aa03d43f1084507751ce50deef073",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "c089183cbdb0907403b901653ea06715e568c811",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegressionTF(BaseEstimator):\n",
    "    def __init__(self, learning_rate, training_epochs, display_step, annotate=False):\n",
    "        self.annotate = annotate\n",
    "        self.sess = tf.Session()\n",
    "        self.training_epochs = training_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.display_step = display_step\n",
    "        \n",
    "        \n",
    "    def fit(self, trainX,trainY):\n",
    "        N = trainX.shape[0]\n",
    "        # 图的输入\n",
    "        self.X = tf.placeholder(\"float\")\n",
    "        self.Y = tf.placeholder(\"float\")\n",
    "        \n",
    "        \n",
    "        # 参数的定义\n",
    "        self.W = tf.Variable(\"W\", name=\"weight\")\n",
    "        self.b = tf.Variable(np.random.randn(), name=\"bias\")\n",
    "        \n",
    "        # 线性模型\n",
    "        self.pred = tf.add(tf.multiply(self.X, self.W), self.b)\n",
    "        \n",
    "        # mean squre error\n",
    "        cost = tf.reduce_sum(tf.pow(self.pred-self.Y, 2))/(2*N)\n",
    "        \n",
    "        # 优化器\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(cost)\n",
    "        \n",
    "        # 初始化所有的参数\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "\n",
    "        \n",
    "        if self.annotate:\n",
    "            plt.plot(trainX, trainY, 'ro', label='Original data')\n",
    "            plt.plot(trainX, self.sess.run(self.W) * trainX + self.sess.run(self.b), label='Fitted line')\n",
    "            plt.legend()\n",
    "            plt.title(\"This is where model starts to learn!!\")\n",
    "            plt.show()\n",
    "            \n",
    "        # 训练开始\n",
    "        for epoch in range(self.training_epochs):\n",
    "            for (x, y) in zip(trainX, trainY):\n",
    "                self.sess.run(optimizer, feed_dict={self.X: x, self.Y: y})\n",
    "\n",
    "            #展示训练结果\n",
    "            if (epoch+1) % display_step == 0:\n",
    "                c = self.sess.run(cost, feed_dict={self.X: trainX, self.Y:trainY})\n",
    "                print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "            \"W=\", self.sess.run(self.W), \"b=\", self.sess.run(self.b))\n",
    "                \n",
    "            #显示拟合的直线\n",
    "                if self.annotate:\n",
    "                    plt.plot(trainX, trainY, 'ro', label='Original data')\n",
    "                    plt.plot(trainX, self.sess.run(self.W) * trainX + self.sess.run(self.b), label='Fitted line')\n",
    "                    plt.legend()\n",
    "                    plt.show()\n",
    "                #plt.pause(0.5)\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "        training_cost = self.sess.run(cost, feed_dict={self.X: trainX, self.Y: trainY})\n",
    "        print(\"Training cost=\", training_cost, \"W=\", self.sess.run(self.W), \"b=\", self.sess.run(self.b), '\\n')\n",
    "\n",
    "        \n",
    "    def predict(self, testX):\n",
    "        prediction = self.sess.run(self.pred,feed_dict={self.X: testX})\n",
    "        return prediction\n",
    "    \n",
    "    def score(self, testX, testY):\n",
    "        result = self.predict(testX)\n",
    "        return r2_score(testY, result)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "0d6b61fe1d7c162a2ad758c6775d93ef331acdd1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LinearRegressionTF(learning_rate, 1000, display_step, annotate=False)\n",
    "lr.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "fe0dbf2cfc47620e3b0d7e742369275e93d70fd1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(lr, trainX, trainY, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "188cda93828598ca757633d2baa9b77c5b7128c2",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3041563fa92a1a5cadb4932657fc94fafc628c83",
    "collapsed": true
   },
   "source": [
    "### 用tensorflow 来实现logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "e90a3afd0ccd8598befebea12c57598c17ad8e40",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "f9f8c89ba6083b2bbba9d3d041f9049d60746c77",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "D = 2\n",
    "trainX = np.random.randn(N, D)\n",
    "\n",
    "delta = 1.75\n",
    "trainX[:N//2] += np.array([delta, delta])\n",
    "trainX[N//2:] += np.array([-delta, -delta])\n",
    "\n",
    "trainY = np.array([0] * (N//2) + [1] * (N//2))\n",
    "plt.scatter(trainX[:,0], trainX[:,1], s=100, c=trainY, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "aeec214e9a265556b6b6d5551dedb1879343f674",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original_label = np.array([0] * (N//2) + [1] * (N//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "16335c02e85b1073873e72a56e52cbebaafa836d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "class LogisticRegressionTF(BaseEstimator):\n",
    "    def __init__(self, learning_rate, training_epochs, display_step, annotate=False):\n",
    "        self.annotate = annotate\n",
    "        self.sess = tf.Session()\n",
    "        self.training_epochs = training_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.display_step = display_step\n",
    "        \n",
    "        \n",
    "    def fit(self, trainX,trainY):\n",
    "        N, D = trainX.shape\n",
    "        _, c = trainY.shape\n",
    "        # 图的输入\n",
    "        self.X = tf.placeholder(tf.float64, shape=[None, D])\n",
    "        self.Y = tf.placeholder(tf.float64, shape=[None, c])\n",
    "        \n",
    "        \n",
    "        # 参数的定义\n",
    "        self.W = tf.Variable(np.random.randn(D,c), name=\"weight\")\n",
    "        self.b = tf.Variable(np.random.randn(c), name=\"bias\")\n",
    "        \n",
    "        # logistic prediction\n",
    "        #self.pred = tf.sigmoid(tf.add(tf.matmul(self.X, self.W), self.b))\n",
    "        output_logits = tf.add(tf.matmul(self.X, self.W), self.b)\n",
    "        self.pred = tf.sigmoid(output_logits)   # turn logits to probability\n",
    "        \n",
    "        # 交叉熵loss\n",
    "        #cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "        cost= tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=output_logits, labels=self.Y))\n",
    "        \n",
    "        # 优化器\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.learning_rate).minimize(cost)\n",
    "        \n",
    "        # 初始化所有的参数\n",
    "        init = tf.global_variables_initializer()\n",
    "        self.sess.run(init)\n",
    "        \n",
    "        \n",
    "        # 可视化初始化的模型边界\n",
    "        if self.annotate:\n",
    "            assert len(trainX.shape) == 2, \"Only 2d points are allowed!!\"\n",
    "\n",
    "            plt.scatter(trainX[:,0], trainX[:,1], s=100, c=original_label, alpha=0.5) \n",
    "\n",
    "            h = .02 \n",
    "            x_min, x_max = trainX[:, 0].min() - 1, trainX[:, 0].max() + 1\n",
    "            y_min, y_max = trainX[:, 1].min() - 1, trainX[:, 1].max() + 1\n",
    "            xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "            Z = self.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "            Z = Z.reshape(xx.shape)\n",
    "            plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "            plt.title(\"This is where model starts to learn!!\")\n",
    "            plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "        # 训练开始\n",
    "        for epoch in range(self.training_epochs):\n",
    "            for (x, y) in zip(trainX, trainY):\n",
    "                self.sess.run(optimizer, feed_dict={self.X: np.asmatrix(x), self.Y: np.asmatrix(y)})\n",
    "\n",
    "            #展示训练结果\n",
    "            if (epoch+1) % display_step == 0:\n",
    "                c = self.sess.run(cost, feed_dict={self.X: trainX, self.Y:trainY})\n",
    "                print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "            \"W=\", self.sess.run(self.W), \"b=\", self.sess.run(self.b))\n",
    "                \n",
    "            #显示拟合的直线\n",
    "                if self.annotate:\n",
    "                    assert len(trainX.shape) == 2, \"Only 2d points are allowed!!\"\n",
    "\n",
    "                    plt.scatter(trainX[:,0], trainX[:,1], s=100, c=original_label, alpha=0.5) \n",
    "             \n",
    "                    h = .02 \n",
    "                    x_min, x_max = trainX[:, 0].min() - 1, trainX[:, 0].max() + 1\n",
    "                    y_min, y_max = trainX[:, 1].min() - 1, trainX[:, 1].max() + 1\n",
    "                    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "                    Z = self.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "                    Z = Z.reshape(xx.shape)\n",
    "                    plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "                    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "        training_cost = self.sess.run(cost, feed_dict={self.X: trainX, self.Y: trainY})\n",
    "        print(\"Training cost=\", training_cost, \"W=\", self.sess.run(self.W), \"b=\", self.sess.run(self.b), '\\n')\n",
    "\n",
    "        \n",
    "    def predict(self, testX):\n",
    "        prediction = self.sess.run(self.pred,feed_dict={self.X: testX})\n",
    "        return np.argmax(prediction, axis=1)\n",
    "    \n",
    "    def score(self, testX, testY):\n",
    "        # suppose the testY has been one hot encoded\n",
    "        #eg:#0: [1,0]  -> 0, 0\n",
    "            #1: [1,0]  -> 1, 0\n",
    "            #2: [0,1]  -> 2, 1\n",
    "        _ , true_result = np.where(testY == 1)\n",
    "        result = self.predict(testX)\n",
    "        return accuracy_score(true_result, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "6a1900bb8783fffab415239b6324ba4edf84430e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "c9a64d19d82c047512a748e30da0a775d401a25e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = OneHotEncoder()\n",
    "le.fit(trainY.reshape(N,-1))\n",
    "trainY = le.transform(trainY.reshape(N,-1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "b5ebe28caf594994b71570e281a3d32ac2463a3e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logisticTF = LogisticRegressionTF(learning_rate, 1000, display_step, annotate=False)\n",
    "logisticTF.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "bca377470fc4b057798c8919f73265622265b40c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(logisticTF, trainX, trainY, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9a0cef56531effeecabd924543bdb8b84141395e"
   },
   "source": [
    "### 用tensorflow来实现KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "_uuid": "bb3747d8baceba10402b08cac9f34a5d1cf134e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "_uuid": "1eeb09e45a4074a3de195254f10e9035523940c4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "#trainX, trainY = mnist.train.next_batch(5000) #5000个数据作为近邻集合\n",
    "#testX, testY = mnist.test.next_batch(200) #200个数据用于测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c14f44b0ef5421cf6eb1b37189a2cd09e87517fc",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "bbdefa17ac0e0055d01dfe8acc0725297365851b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_folder = \"../input/ninechapterdigitsub\"\n",
    "#data_folder = \"data\"\n",
    "trainX = np.genfromtxt(os.path.join(data_folder, \"digit_mnist_trainx.csv\"), delimiter=',')\n",
    "trainY = np.genfromtxt(os.path.join(data_folder, \"digit_mnist_trainy.csv\"), delimiter=',')\n",
    "testX = np.genfromtxt(os.path.join(data_folder, \"digit_mnist_testx.csv\"), delimiter=',')\n",
    "testY = np.genfromtxt(os.path.join(data_folder, \"digit_mnist_testy.csv\"), delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4373a1bc274569a9df6fc54df3c5968500bfd3fa",
    "collapsed": true
   },
   "source": [
    "### define your computing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "8c4f49419a73a712f13f2a22ecfbd32f0fc15fff",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr = tf.placeholder(\"float\", [None, 784])\n",
    "xte = tf.placeholder(\"float\", [784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "4ba548544bd8ba4d88807f836d3bce36e9e1ee77",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distance = tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(xtr, xte)), reduction_indices=1))\n",
    "\n",
    "# train 0: [1,...1]\n",
    "# train 1: [0,...0]\n",
    "# test : [1,...1]\n",
    "# tf.subtract(xtr, xte):\n",
    "#  0: [0,...0]\n",
    "#  1: [-1,...-1]\n",
    "# tf.square:\n",
    "#  0: [0,...0]\n",
    "#  1: [1,...1]\n",
    "#  tf.reduce_sum(tf.square(tf.subtract(xtr, xte)), reduction_indices=1):\n",
    "#  0: [0]\n",
    "#  1: [784]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "_uuid": "860a83a6d46e51d6f135d30fa258ea8572a3485e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 因为是topk大的值，这里distance取负号\n",
    "KVALUE = 1\n",
    "pred= tf.nn.top_k(-distance, k=KVALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "_uuid": "770f1cb9f04269a9800acda73c6ce216217bb224",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "accuracy = 0.\n",
    "\n",
    "# 初始化参数\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "\n",
    "# 开始训练\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # 预测测试数据的标签 (passive learner)\n",
    "    for i in range(len(testX)):\n",
    "        # 最近邻的序号\n",
    "        values, knn_index = sess.run(pred, feed_dict={xtr: trainX, xte: testX[i, :]})\n",
    "\n",
    "        # 拿到k个邻居后做全民公投，得票最多的为预测标签\n",
    "        c = Counter(np.argmax(trainY[knn_index], axis=1))\n",
    "        result = c.most_common(KVALUE)[0][0]\n",
    "        # 计算最近邻的标签和真实标签值\n",
    "        print(\"Test\", i, \"Prediction:\", result, \\\n",
    "            \"True Class:\", np.argmax(testY[i]))\n",
    "        # 正确率\n",
    "        if result == np.argmax(testY[i]):\n",
    "\n",
    "            accuracy += 1./len(testX)\n",
    "    print(\"Done!\")\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "df46db7723f3ab4e881233d6ba175078d98ab8d4"
   },
   "source": [
    "### 用tensorflow 实现naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "c77618f3d391f0ba80fe5bcbb4710e2146bbe049",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "13e6dff3f4d79326fb6e383e9096ad30c4ec711c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 120\n",
    "D = 2\n",
    "trainX = np.random.randn(N, D)\n",
    "\n",
    "delta = 2\n",
    "#trainX[:N//3] += np.array([delta, delta])\n",
    "#trainX[N//3:N*2//3] += np.array([-delta, delta])\n",
    "#trainX[N*2//3:] += np.array([0, -delta])\n",
    "\n",
    "\n",
    "delta = 1.75\n",
    "trainX[:N//2] += np.array([delta, delta])\n",
    "trainX[N//2:] += np.array([-delta, -delta])\n",
    "\n",
    "trainY = np.array([0] * (N//2) + [1] * (N//2))\n",
    "plt.scatter(trainX[:,0], trainX[:,1], s=100, c=trainY, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "67a2139d734d47d85cec0b028f3be82c0c1b6d35",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "9bb7f9358b55cd9d4f58ecf03af3018d2522fd70",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import colors\n",
    "from sklearn.utils.fixes import logsumexp\n",
    "\n",
    "\n",
    "class NaiveBayesTF(BaseEstimator):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.dist = None\n",
    "        self.sess = tf.Session()\n",
    "\n",
    "    def fit(self, trainX, trainY):\n",
    "        # Separate training points by class (nb_classes * nb_samples * nb_features)\n",
    "        unique_classes = np.unique(trainY)\n",
    "        points_by_class = np.array([\n",
    "            [x for x, y in zip(trainX, trainY) if y == c]\n",
    "            for c in unique_classes])\n",
    "        \n",
    "        input_x = tf.placeholder(tf.float64, shape=points_by_class.shape)\n",
    "        # 估计每个类底下每一种feature的均值和方差\n",
    "        # shape: num_classes * nb_features\n",
    "        \n",
    "        moments = tf.nn.moments(input_x, axes=[1])\n",
    "        mean, var = self.sess.run(moments, feed_dict={input_x:points_by_class})\n",
    "        #print(mean.shape)\n",
    "        #print(var.shape)\n",
    "        \n",
    "        # 点集实验里为2类，每个数据点有2个特征 \n",
    "        # known mean and variance\n",
    "        self.dist = tf.distributions.Normal(loc=mean, scale=tf.sqrt(var))\n",
    "        \n",
    "\n",
    "    def predict(self, testX):\n",
    "        assert self.dist is not None\n",
    "        num_classes, num_features = map(int, self.dist.scale.shape)\n",
    "\n",
    "        # 条件概率 log P(x|c)\n",
    "        # (nb_samples, nb_classes)\n",
    "        cond_probs = tf.reduce_sum(\n",
    "            self.dist.log_prob(\n",
    "                tf.reshape(\n",
    "                    tf.tile(testX, [1, num_classes]), [-1, num_classes, num_features])),\n",
    "            axis=2)\n",
    "        \n",
    "        # 第一个点: 2.0,3.5\n",
    "        # 第二个点: 0.5,1.4\n",
    "        # tf.tile (num_classes = 2):\n",
    "        # 第一个点: 2.0,3.5,2.0,3.5\n",
    "        # 第二个点: 0.5,1.4,0.5,1.4\n",
    "        # tf.reshape:\n",
    "        # 第一个点: 2.0,3.5 \n",
    "        #         2.0,3.5\n",
    "        # 第二个点：0.5,1.4\n",
    "        #         0.5,1.4\n",
    "\n",
    "        # P(C) 均匀分布\n",
    "        priors = np.log(np.array([1. / num_classes] * num_classes))\n",
    "\n",
    "        # 后验概率取log, log P(C) + log P(x|C)\n",
    "        posterior = tf.add(priors, cond_probs)\n",
    "        \n",
    "        # 取概率最大的那一个\n",
    "        result = self.sess.run(tf.argmax(posterior, axis=1))\n",
    "\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def score(self, testX, testY):\n",
    "        result = self.predict(testX)\n",
    "        return accuracy_score(testY, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "69c8fae1921c786d6d68866a6d118e31fecacfa5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_nb = NaiveBayesTF()\n",
    "tf_nb.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "3a92d8f5470066ca99e6d5a12489d73589ea13ec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_min, x_max = trainX[:, 0].min() - .5, trainX[:, 0].max() + .5\n",
    "y_min, y_max = trainX[:, 1].min() - .5, trainX[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 30),\n",
    "                     np.linspace(y_min, y_max, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_uuid": "363a7e31ef97c9eec7cb01efec7a660e8d9472a4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = tf_nb.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_uuid": "1f70b671eb32f72c4a8323cffcc4d7a870042707",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "27eef12fd8d94d589c74101f1fefe7e9665e875a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(trainX[:,0], trainX[:,1], s=100, c=trainY, alpha=0.5)\n",
    "plt.contour(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "c974982897bd5aa898c1057cc31f9d9a12473782",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_nb.score(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d6742dea4b760221bb21c1fe83b4fefc7c26a7c5",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5d284b0df80721cf8a098f0092d51cdfa48c4cbc",
    "collapsed": true
   },
   "source": [
    "### Tensorflow实现random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4325553138f896c9f0aac9422872230666e3c5c",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "fb6a5f6d9122cb82db8b4c9084c2f613ef4e0d5e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "from tensorflow.python.ops import resources\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "970e14bd534de0686d19dab98e29a10405c83d6f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = \"../input/fashionmnist\"\n",
    "#data_folder = \"./data\"\n",
    "train_data = pd.read_csv(os.path.join(data_folder, \"fashion-mnist_train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(data_folder, \"fashion-mnist_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "_uuid": "11677043b47c85766a3702ab42ec4c89f6c4dd36",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = np.array(train_data.iloc[:, 1:])\n",
    "trainY = np.array(train_data.iloc[:, 0])\n",
    "testX = np.array(test_data.iloc[:, 1:])\n",
    "testY = np.array(test_data.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_uuid": "ddfaa0e7c50325de06229a640ca4f838ebaa7b55",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_CLASSES = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_uuid": "351904ee51ca09fcde088b691250e839b1933c7c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img_size = 28\n",
    "for img, label in zip(trainX[:10], trainY[:10]):\n",
    "    plt.imshow(img.reshape(img_size,img_size),cmap='gray')\n",
    "    plt.title(IMAGE_CLASSES[label])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_uuid": "af39b7b109c8aea38e01f3366d03a7740cb1b396",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 参数设定\n",
    "#The 10 categories\n",
    "#784 Each image is 28x28 pixels\n",
    "num_steps = 100# Total steps to train\n",
    "batch_size = 1024 # The number of samples per batch\n",
    "num_trees = 10\n",
    "max_nodes = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "52683c22745ade5fbf0b9dc3f8e58eba41da2150",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_uuid": "e781afd873e74277d5c7d08322a84ec59a3c8b92",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "class RandomForestTF(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, num_trees):\n",
    "        self.num_trees = num_trees\n",
    "        \n",
    "    def fit(self, X, Y, num_steps, batch_size,max_nodes):\n",
    "        num_classes = 10   #len(IMAGE_CLASSES)\n",
    "        num_data = X.shape[0]\n",
    "        num_features = X.shape[1]\n",
    "        \n",
    "        self.X = tf.placeholder(tf.float32, shape=[None, num_features]) \n",
    "        self.Y = tf.placeholder(tf.int32, shape=[None]) \n",
    "        \n",
    "        \n",
    "        # 随机森林的参数\n",
    "        hparams = tensor_forest.ForestHParams(num_classes=num_classes,\n",
    "                                      num_features=num_features,\n",
    "                                      num_trees=self.num_trees,\n",
    "                                      max_nodes=max_nodes).fill()\n",
    "        \n",
    "        \n",
    "        # 随机森林的计算图\n",
    "        forest_graph = tensor_forest.RandomForestGraphs(hparams)\n",
    "        \n",
    "        train_operation = forest_graph.training_graph(self.X, self.Y)\n",
    "        loss_operation = forest_graph.training_loss(self.X, self.Y)\n",
    "        \n",
    "        # inference_graph will return probabilities, decision path and variance\n",
    "        self.infer_op, _, _ = forest_graph.inference_graph(self.X)\n",
    "        correct_prediction = tf.equal(tf.argmax(self.infer_op, 1), tf.cast(self.Y, tf.int64))\n",
    "        self.accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        \n",
    "        # 将初始化的操作和树的参数初始化 作为一个整体操作\n",
    "        init_vars = tf.group(tf.global_variables_initializer(),\n",
    "                   resources.initialize_resources(resources.shared_resources()))\n",
    "        #init_vars = tf.global_variables_initializer()\n",
    "        \n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init_vars)\n",
    "\n",
    "        # 开始训练\n",
    "        cnt = 0\n",
    "        for i in range(1, num_steps + 1):\n",
    "            # Prepare Data\n",
    "            # 每次学习一个batch的MNIST data\n",
    "            #batch_x, batch_y = training_set.next_batch(batch_size)\n",
    "            start, end = ((i-1) * batch_size) % num_data, (i * batch_size) % num_data\n",
    "            \n",
    "            batch_x, batch_y = X[start:end], Y[start:end]\n",
    "            _, l = self.sess.run([train_operation, loss_operation], feed_dict={self.X: batch_x, self.Y: batch_y})\n",
    "            if i % 50 == 0 or i == 1:\n",
    "                acc = self.sess.run(self.accuracy_op, feed_dict={self.X: batch_x, self.Y: batch_y})\n",
    "                print('Step %i, Loss: %f, Acc: %f' % (i, l, acc))\n",
    "                \n",
    "    def predict(self, testX):\n",
    "        results = self.sess.run(self.infer_op, feed_dict={self.X:testX})\n",
    "        return np.argmax(results, axis=1)\n",
    "    \n",
    "    def score(self, testX, testY):\n",
    "        accuracy = self.sess.run(self.accuracy_op, feed_dict={self.X: testX, self.Y: testY})\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "_uuid": "ce9440c4116c2586e3ae84f9160cae2401793d1a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rftf = RandomForestTF(num_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_uuid": "3741234913e705ddb4780c7c7c1fe989de5b50f1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rftf.fit(trainX, trainY, num_steps, batch_size, max_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_uuid": "04be03cd880f34cb1e51fc0e029e2429596890d0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rftf.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cf0eb50e27db15dcd256619d012e0fd55866e55",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
